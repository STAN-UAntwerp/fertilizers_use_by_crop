{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import os\n",
    "os.environ['TARGET'] = 'K2O_avg_app'\n",
    "\n",
    "sys.path.append(Path('.').absolute().parent.resolve().as_posix())\n",
    "sys.path.append((Path('.').absolute().parent / 'source').resolve().as_posix())\n",
    "from data_loader import config_loader, data_preprocessing\n",
    "from logging_util.logger import get_logger\n",
    "from models import estimators\n",
    "from evaluation import evaluation\n",
    "\n",
    "config = config_loader.load_config(fertilizer=os.getenv('TARGET'))\n",
    "logger = get_logger(__name__)\n",
    "logging.getLogger(\"PIL\").setLevel(logging.WARNING)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set resultspath\n",
    "\n",
    "resultspath = Path().resolve().parent / 'results_corrected'\n",
    "resultspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to initialize estimator\n",
    "def init_estimator(estimator_name: str = 'HistGradientBoostRegressor', resultspath: Path = resultspath, fold: int = 0):\n",
    "\n",
    "    estimator_cls = estimators[estimator_name]\n",
    "    estimator = estimator_cls(outpath=resultspath)\n",
    "    estimator = estimator.load(path=estimator.output_path, it=fold)\n",
    "\n",
    "    return estimator\n",
    "\n",
    "# function to make predictions\n",
    "def make_predictions(input_data: pd.DataFrame, target: str = 'N_avg_app', estimator_name: str = 'HistGradientBoostRegressor', resultspath: Path = resultspath, fold: int = 0) -> tuple:\n",
    "\n",
    "    estimator = init_estimator(estimator_name, resultspath / target, fold)\n",
    "    y_pred = pd.Series(\n",
    "        estimator.model.predict(input_data),\n",
    "        index=input_data.index,\n",
    "        name=f'predicted_{target}',\n",
    "    )\n",
    "    dataset_with_preds = input_data.join(y_pred)\n",
    "    dataset_with_preds.to_csv(resultspath / target / estimator.abbrev / f'full_predictions_{fold}.csv')\n",
    "\n",
    "    return y_pred, dataset_with_preds\n",
    "\n",
    "# all_data = data_preprocessing.load_all_data()\n",
    "# all_data = data_preprocessing.one_hot_encoding(all_data)\n",
    "# make_predictions(input_data=all_data, target=target, estimator_name=estimator_name, resultspath=resultspath, fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all predictions\n",
    "all_data = data_preprocessing.load_all_data()\n",
    "all_data = data_preprocessing.one_hot_encoding(all_data)\n",
    "for estimator_name, _ in estimators.items():\n",
    "    # for target in ['N_avg_app', 'P2O5_avg_app', 'K2O_avg_app']:\n",
    "    for fold in [0, 1]:\n",
    "        make_predictions(input_data=all_data, target=os.getenv('TARGET'), estimator_name=estimator_name, resultspath=resultspath, fold=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_folds(target: str = 'N_avg_app', estimator_abbrev: str = 'HGB', resultspath: Path = resultspath):\n",
    "    \"\"\"Merge the folds of a model into a single dataframe\"\"\"\n",
    "\n",
    "    preds_0 = pd.read_csv(resultspath / f'{target}/{estimator_abbrev}/full_predictions_0.csv')\n",
    "    preds_1 = pd.read_csv(resultspath / f'{target}/{estimator_abbrev}/full_predictions_1.csv')\n",
    "\n",
    "    test_0 = pd.read_csv(resultspath / f'{target}/data/test_set_0.csv')\n",
    "    test_1 = pd.read_csv(resultspath / f'{target}/data/test_set_1.csv')\n",
    "\n",
    "    testpreds_0 = pd.read_csv(resultspath / f'{target}/{estimator_abbrev}/predictions_0.csv')\n",
    "    testpreds_1 = pd.read_csv(resultspath / f'{target}/{estimator_abbrev}/predictions_1.csv')\n",
    "\n",
    "    # get r2 values for each fold\n",
    "    metrics_path = resultspath / target / 'performance_metrics_test.csv'\n",
    "    metrics = pd.read_csv(metrics_path)\n",
    "    metrics.columns = ['metric', 'estimator_abbrev', 'mean', 'std', '0', '1']\n",
    "    r2_0 = metrics.loc[(metrics['metric'] == 'R2') & (metrics['estimator_abbrev'] == estimator_abbrev), '0'].to_numpy()[0]\n",
    "    r2_1 = metrics.loc[(metrics['metric'] == 'R2') & (metrics['estimator_abbrev'] == estimator_abbrev), '1'].to_numpy()[0]\n",
    "\n",
    "    # load original dataset\n",
    "    dtypes = data_preprocessing.get_data_types(config=config)\n",
    "    dtypes['N_avg_app'] = np.float64\n",
    "    dtypes['P2O5_avg_app'] = np.float64\n",
    "    dtypes['K2O_avg_app'] = np.float64\n",
    "    all_data = data_preprocessing.load_all_data(config=config, dtype=dtypes)\n",
    "    final_data = all_data.copy()\n",
    "\n",
    "    # find indices where NOT (all three fertilizers are known and N_avg_app < 5000)\n",
    "    idx_unlabeled_fertilizers = all_data.loc[~(\n",
    "        ~all_data['N_avg_app'].isna() & \n",
    "        ~all_data['P2O5_avg_app'].isna() & \n",
    "        ~all_data['K2O_avg_app'].isna() & \n",
    "        (all_data['N_avg_app'] < 5000)\n",
    "        )].index\n",
    "\n",
    "\n",
    "    # merge predictions for samples not in test/train sets\n",
    "    subset_0 = preds_0.loc[idx_unlabeled_fertilizers]\n",
    "    subset_1 = preds_1.loc[idx_unlabeled_fertilizers]\n",
    "\n",
    "    weight_0, weight_1 = r2_0 / (r2_0 + r2_1), r2_1 / (r2_0 + r2_1)\n",
    "    weighted_preds = weight_0 * subset_0[f'predicted_{target}'] + weight_1 * subset_1[f'predicted_{target}']\n",
    "    final_data.loc[idx_unlabeled_fertilizers, f'predicted_{target}'] = weighted_preds\n",
    "\n",
    "    ## Test/Train predictions\n",
    "\n",
    "    # add preds to test sets\n",
    "    test_0_with_preds = test_0.copy()\n",
    "    test_0_with_preds[f'predicted_{target}'] = testpreds_0[f'predicted_{target}']\n",
    "    test_1_with_preds = test_1.copy()\n",
    "    test_1_with_preds[f'predicted_{target}'] = testpreds_1[f'predicted_{target}']\n",
    "\n",
    "    # match the indices of the test sets with the indices of the predictions\n",
    "\n",
    "    # using columns 'FAOStat_area_code', 'Year', 'Crop_Code', and the target\n",
    "    # we can match the indices of the test sets with the indices of the predictions\n",
    "\n",
    "    final_data['temp'] = final_data['FAOStat_area_code'].astype(str) + final_data['Year'].astype(str) + final_data['Crop_Code'].astype(str) + final_data[target].astype(str)\n",
    "    test_0_with_preds['temp'] = test_0_with_preds['FAOStat_area_code'].astype(str) + test_0_with_preds['Year'].astype(str) + test_0_with_preds['Crop_Code'].astype(str) + test_0_with_preds[target].astype(str)\n",
    "    test_1_with_preds['temp'] = test_1_with_preds['FAOStat_area_code'].astype(str) + test_1_with_preds['Year'].astype(str) + test_1_with_preds['Crop_Code'].astype(str) + test_1_with_preds[target].astype(str)\n",
    "\n",
    "    # match the indices of test_0_with_preds with the indices of final_data and fill in the predictions\n",
    "    test_0_with_preds = test_0_with_preds.set_index('temp')\n",
    "    test_1_with_preds = test_1_with_preds.set_index('temp')\n",
    "    final_data = final_data.set_index('temp')\n",
    "    final_data.loc[test_0_with_preds.index, f'predicted_{target}'] = test_0_with_preds[f'predicted_{target}']\n",
    "    final_data.loc[test_1_with_preds.index, f'predicted_{target}'] = test_1_with_preds[f'predicted_{target}']\n",
    "    final_data = final_data.reset_index()\n",
    "    final_data.drop(columns=['temp', 'N_avg_app', 'P2O5_avg_app', 'K2O_avg_app'], inplace=True)\n",
    "\n",
    "    # if any values in the final dataset are < 0, set them to 0\n",
    "    final_data[f'predicted_{target}'] = final_data[f'predicted_{target}'].clip(lower=0)\n",
    "\n",
    "    # sanity check: are all predictions filled in?\n",
    "    if final_data[f'predicted_{target}'].isna().sum() > 0:\n",
    "        print(f'WARNING: {final_data[f\"predicted_{target}\"].isna().sum()} predictions are missing for {target},{estimator_abbrev}')\n",
    "\n",
    "    # save the merged predictions\n",
    "    final_data.to_csv(resultspath / f'{target}/{estimator_abbrev}/full_predictions_merged.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_abbrev in ['HGB', 'XGB']:\n",
    "    # for target in ['N_avg_app', 'P2O5_avg_app', 'K2O_avg_app']:\n",
    "    merge_folds(target=os.getenv('TARGET'), estimator_abbrev=estimator_abbrev, resultspath=resultspath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fertilizer_usage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
